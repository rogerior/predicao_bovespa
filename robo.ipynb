{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auto Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import sklearn\n",
    "import csv\n",
    "from sklearn import tree, svm, naive_bayes, neighbors, ensemble, calibration, gaussian_process, semi_supervised, discriminant_analysis\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.decomposition import PCA, NMF, FastICA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from datetime import datetime\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lendo os arquivos tratados de todas as ações\n",
    "dados = pd.read_csv('dados/dados_tratados_acoes_atuais.csv')\n",
    "dados.sort_values('DATA', ascending=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lista com todas as técnicas para serem executadas\n",
    "tecnicas = [ ('AdaBoostClassifier', sklearn.ensemble.weight_boosting.AdaBoostClassifier()),\n",
    "             ('BaggingClassifier', sklearn.ensemble.bagging.BaggingClassifier()),\n",
    "             ('BernoulliNB', sklearn.naive_bayes.BernoulliNB()),\n",
    "             ('CalibratedClassifierCV', sklearn.calibration.CalibratedClassifierCV()),\n",
    "             ('DecisionTreeClassifier', sklearn.tree.tree.DecisionTreeClassifier()),\n",
    "             ('ExtraTreeClassifier', sklearn.tree.tree.ExtraTreeClassifier()),\n",
    "             ('ExtraTreesClassifier', sklearn.ensemble.forest.ExtraTreesClassifier()),\n",
    "             #('GaussianNB', sklearn.naive_bayes.GaussianNB()),\n",
    "             ('GaussianProcessClassifier', sklearn.gaussian_process.gpc.GaussianProcessClassifier()),\n",
    "             ('GradientBoostingClassifier', sklearn.ensemble.gradient_boosting.GradientBoostingClassifier()),\n",
    "             ('KNeighborsClassifier', sklearn.neighbors.classification.KNeighborsClassifier()),\n",
    "             ('LabelPropagation', sklearn.semi_supervised.label_propagation.LabelPropagation()),\n",
    "             ('LabelSpreading', sklearn.semi_supervised.label_propagation.LabelSpreading()),\n",
    "             ('LinearDiscriminantAnalysis', sklearn.discriminant_analysis.LinearDiscriminantAnalysis()),\n",
    "             ('LinearSVC', sklearn.svm.classes.LinearSVC()),\n",
    "             ('LogisticRegression', sklearn.linear_model.logistic.LogisticRegression(penalty='l2')),\n",
    "             ('LogisticRegressionCV', sklearn.linear_model.logistic.LogisticRegressionCV()),\n",
    "             ('MLPClassifier', sklearn.neural_network.multilayer_perceptron.MLPClassifier()),\n",
    "             ('MultinomialNB', sklearn.naive_bayes.MultinomialNB()),\n",
    "             ('NearestCentroid', sklearn.neighbors.nearest_centroid.NearestCentroid()),\n",
    "             #('NuSVC', sklearn.svm.classes.NuSVC()), # erro de outlier\n",
    "             ('PassiveAggressiveClassifier', sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier()),\n",
    "             ('Perceptron', sklearn.linear_model.perceptron.Perceptron()),\n",
    "             ('QuadraticDiscriminantAnalysis', sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis()),\n",
    "             ('RadiusNeighborsClassifier', sklearn.neighbors.classification.RadiusNeighborsClassifier()),\n",
    "             ('RandomForestClassifier', sklearn.ensemble.forest.RandomForestClassifier()),\n",
    "             ('RidgeClassifier', sklearn.linear_model.ridge.RidgeClassifier()),\n",
    "             ('RidgeClassifierCV', sklearn.linear_model.ridge.RidgeClassifierCV()),\n",
    "             ('SGDClassifier', sklearn.linear_model.stochastic_gradient.SGDClassifier())#,\n",
    "             #('SVC', sklearn.svm.classes.SVC())\n",
    "           ]\n",
    "\n",
    "    \n",
    "len(tecnicas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para gravar o log das etapas realizadas\n",
    "def gravarLog(tipo, mensagem): \n",
    "    \n",
    "    #print(str(datetime.now())+'; ['+tipo+']; ' + str(mensagem))\n",
    "    \n",
    "    if tipo == 'resultado':\n",
    "        nomeArquivo = 'resultados_tecnicas.csv'\n",
    "        with open(nomeArquivo, 'a', newline='') as arquivo:\n",
    "            writer = csv.DictWriter(arquivo, fieldnames=['acao','accuracy','roc_auc_score','f1_score','log_loss','precision','recall','tecnica','tipo_split','pipeline','parametros','best_estimator','best_params','random_state_split','random_state_random_search','cross_validation_random_search','tamanho_base_treino','tamanho_base_teste','tamanho_base_completa','tem_dados_de_teste_nos_dados_de_treino'], delimiter=';')\n",
    "            if arquivo.tell() == 0:\n",
    "                writer.writeheader()\n",
    "            #writer.writerow({'mensagem': str(mensagem['tecnica'])})  \n",
    "            \n",
    "            writer.writerow({\n",
    "            'acao': mensagem['acao'], \n",
    "            'accuracy': mensagem['accuracy'],\n",
    "            'roc_auc_score': mensagem['roc_auc_score'],\n",
    "            'f1_score': mensagem['f1_score'],\n",
    "            'log_loss': mensagem['log_loss'],\n",
    "            'precision': mensagem['precision'],\n",
    "            'recall': mensagem['recall'],\n",
    "            'tecnica': mensagem['tecnica'],\n",
    "            'tipo_split': mensagem['tipo_split'],\n",
    "            'pipeline':mensagem['pipeline'],\n",
    "            'parametros':mensagem['parametros'],\n",
    "            'best_estimator':mensagem['best_estimator'],\n",
    "            'best_params':mensagem['best_params'],\n",
    "            'random_state_split':mensagem['random_state_split'],\n",
    "            'random_state_random_search':mensagem['random_state_random_search'],\n",
    "            'cross_validation_random_search':mensagem['cross_validation_random_search'],\n",
    "            'tamanho_base_treino':mensagem['tamanho_base_treino'],\n",
    "            'tamanho_base_teste':mensagem['tamanho_base_teste'],\n",
    "            'tamanho_base_completa':mensagem['tamanho_base_completa'],\n",
    "            'tem_dados_de_teste_nos_dados_de_treino':mensagem['tem_dados_de_teste_nos_dados_de_treino']\n",
    "            })\n",
    "            \n",
    "            \n",
    "    \n",
    "    nomeArquivo = 'log/log.csv'\n",
    "    with open(nomeArquivo, 'a', newline='') as arquivo:\n",
    "        writer = csv.DictWriter(arquivo, fieldnames=['horario', 'tipo', 'mensagem'], delimiter=';')\n",
    "        if arquivo.tell() == 0:\n",
    "            writer.writeheader()\n",
    "        writer.writerow({'horario': str(datetime.now()),'tipo': tipo, 'mensagem': mensagem})   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para retornar os dados de uma ação já separados em X e y\n",
    "def getDadosAcao(acao):\n",
    "    dados_acao = dados.loc[dados['CODNEG'] == acao]\n",
    "    \n",
    "    dados_acao.sort_values('DATA', ascending=True, inplace=True)\n",
    "\n",
    "    X = dados_acao.copy()\n",
    "    X.drop(['CODNEG', 'DATA', 'STATUS_POSITIVO'], axis=1, inplace=True)\n",
    "    y = dados_acao['STATUS_POSITIVO']\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para separar os dados de treino e teste, escolhendo a forma de separar os dados aleatoriamente\n",
    "def splitDados(X, y):\n",
    "    \n",
    "    aleatorio = getNumeroAleatorio('simples', 6)\n",
    "    \n",
    "    random_state = getNumeroAleatorio('random_state')\n",
    "    \n",
    "    if aleatorio == 0:\n",
    "        tipo_split = 'train_test_split 20%'\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
    "    elif aleatorio == 1:\n",
    "        tipo_split = 'train_test_split 25%'\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=random_state)\n",
    "    elif aleatorio == 2:\n",
    "        tipo_split = 'train_test_split 30%'\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=random_state)\n",
    "    elif aleatorio == 3:\n",
    "        tipo_split = '30 ultimos dias'\n",
    "        X_train = X[:-30]\n",
    "        y_train = y[:-30]\n",
    "        X_test = X.iloc[-30:]\n",
    "        y_test = y.iloc[-30:]\n",
    "    elif aleatorio == 4:\n",
    "        tipo_split = '60 ultimos dias'\n",
    "        X_train = X[:-60]\n",
    "        y_train = y[:-60]\n",
    "        X_test = X.iloc[-60:]\n",
    "        y_test = y.iloc[-60:]\n",
    "    elif aleatorio == 5:\n",
    "        tipo_split = '90 ultimos dias'\n",
    "        X_train = X[:-90]\n",
    "        y_train = y[:-90]\n",
    "        X_test = X.iloc[-90:]\n",
    "        y_test = y.iloc[-90:]\n",
    "    elif aleatorio == 6:\n",
    "        tipo_split = '180 ultimos dias'\n",
    "        X_train = X[:-180]\n",
    "        y_train = y[:-180]\n",
    "        X_test = X.iloc[-180:]\n",
    "        y_test = y.iloc[-180:]\n",
    "    \n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, tipo_split, random_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retorna aleatoriamente qual normalizador será utilizado\n",
    "def getNormalizador():\n",
    "    normalizador = [(),\n",
    "                    ('standard_scaler', sklearn.preprocessing.StandardScaler()),\n",
    "                    ('robust_scaler', sklearn.preprocessing.RobustScaler()),\n",
    "                    ('min_max_scaler', sklearn.preprocessing.MinMaxScaler()),\n",
    "                    ('normalizer', sklearn.preprocessing.Normalizer())\n",
    "                   ]\n",
    "    \n",
    "    aleatorio = getNumeroAleatorio('simples', len(normalizador)-1)\n",
    "    \n",
    "    if aleatorio == 0:\n",
    "        parametros = {}\n",
    "    elif normalizador[aleatorio][0] == 'standard_scaler':\n",
    "        parametros = {\n",
    "            'standard_scaler__with_mean': [True, False],\n",
    "            'standard_scaler__with_std': [True, False]\n",
    "        }\n",
    "    elif normalizador[aleatorio][0] == 'robust_scaler':\n",
    "        parametros = {\n",
    "            'robust_scaler__with_centering': [True, False],\n",
    "            'robust_scaler__with_scaling': [True, False]\n",
    "        }\n",
    "    elif normalizador[aleatorio][0] == 'min_max_scaler':\n",
    "        parametros = {\n",
    "            'min_max_scaler__feature_range': [(0,1), (1,10), (1,100)]\n",
    "        }\n",
    "    elif normalizador[aleatorio][0] == 'normalizer':\n",
    "        parametros = {\n",
    "            'normalizer__norm': ('l1', 'l2', 'max')\n",
    "        }\n",
    "        \n",
    "    \n",
    "    return normalizador[aleatorio], parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retorna aleatoriamente qual redutor de dimensionalidade será utilizado\n",
    "def getRedutorDimensionalidade():\n",
    "    redutor_dimensionalidade = [(),\n",
    "                                ('pca', PCA()),\n",
    "                                ('nmf', NMF()),\n",
    "                                ('FastICA', FastICA())]\n",
    "    \n",
    "    aleatorio = getNumeroAleatorio('simples', len(redutor_dimensionalidade)-1)\n",
    "    \n",
    "    if aleatorio == 0:\n",
    "        parametros = {}\n",
    "    elif redutor_dimensionalidade[aleatorio][0] == 'pca':\n",
    "        parametros = {\n",
    "            'pca__n_components': [None, 3, 5, 7, 9, 11, 13],\n",
    "            'pca__whiten': [True, False],\n",
    "            'pca__svd_solver': ('auto', 'full', 'randomized')\n",
    "        }\n",
    "    elif redutor_dimensionalidade[aleatorio][0] == 'nmf':\n",
    "        parametros = {\n",
    "            'nmf__n_components': [None, 3, 5, 7, 9, 11, 13],\n",
    "            'nmf__init': ('random', 'nndsvd', 'nndsvda', 'nndsvdar'),\n",
    "            'nmf__solver': ('cd', 'mu')\n",
    "        }\n",
    "    elif redutor_dimensionalidade[aleatorio][0] == 'FastICA':\n",
    "        parametros = {\n",
    "            'FastICA__n_components': [None, 3, 5, 7, 9, 11, 13],\n",
    "            'FastICA__algorithm': ('parallel', 'deflation'),\n",
    "            'FastICA__whiten': [True, False]\n",
    "        }\n",
    "        \n",
    "    \n",
    "    return redutor_dimensionalidade[aleatorio], parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recebe uma técnica e retorna os parametros da técnica\n",
    "def getParametrosTecnica(tecnica):\n",
    "    if tecnica == 'AdaBoostClassifier':\n",
    "        parametros = {\n",
    "            'AdaBoostClassifier__n_estimators': [5,25,50,75,100],\n",
    "            'AdaBoostClassifier__learning_rate': [0.5, 1.0, 1.5],\n",
    "            'AdaBoostClassifier__algorithm': ('SAMME', 'SAMME.R')\n",
    "        }\n",
    "    elif tecnica == 'BaggingClassifier':\n",
    "        parametros = {\n",
    "            'BaggingClassifier__n_estimators': [5, 10, 15],\n",
    "            #'BaggingClassifier__bootstrap': [True, False],\n",
    "            'BaggingClassifier__bootstrap_features': [True, False],\n",
    "            'BaggingClassifier__oob_score': [True, False]\n",
    "        }\n",
    "    elif tecnica == 'BernoulliNB':\n",
    "        parametros = {\n",
    "            'BernoulliNB__alpha': [0, 0.5, 1.0, 1.5, 2],\n",
    "            'BernoulliNB__fit_prior': [True, False]\n",
    "        }\n",
    "    elif tecnica == 'CalibratedClassifierCV':\n",
    "        parametros = {\n",
    "            'CalibratedClassifierCV__method': ('sigmoid', 'isotonic'),\n",
    "            'CalibratedClassifierCV__cv': [3, 5, 10]\n",
    "        }\n",
    "    elif tecnica == 'DecisionTreeClassifier':\n",
    "        parametros = {\n",
    "            'DecisionTreeClassifier__criterion': ('gini', 'entropy'),\n",
    "            'DecisionTreeClassifier__splitter': ('best', 'random')            \n",
    "        }\n",
    "    elif tecnica == 'ExtraTreeClassifier':\n",
    "        parametros = {\n",
    "            'ExtraTreeClassifier__criterion': ('gini', 'entropy'),\n",
    "            'ExtraTreeClassifier__max_features': ('auto', 'sqrt', 'log2')\n",
    "        }\n",
    "    elif tecnica == 'ExtraTreesClassifier':\n",
    "        parametros = {\n",
    "            'ExtraTreesClassifier__criterion': ('gini', 'entropy'),\n",
    "            'ExtraTreesClassifier__max_features': ('auto', 'sqrt', 'log2')\n",
    "            #\n",
    "        }\n",
    "    elif tecnica == 'GaussianProcessClassifier':\n",
    "        parametros = {\n",
    "            'GaussianProcessClassifier__n_restarts_optimizer': [0,5,10,15],\n",
    "            'GaussianProcessClassifier__max_iter_predict': [10, 100, 1000]\n",
    "        }  \n",
    "    elif tecnica == 'GradientBoostingClassifier':\n",
    "        parametros = {\n",
    "            'GradientBoostingClassifier__loss': ('deviance', 'exponential'),\n",
    "            'GradientBoostingClassifier__learning_rate': [0.1,0.2,0.001],\n",
    "            'GradientBoostingClassifier__criterion': ('friedman_mse', 'mse', 'mae'),\n",
    "            'GradientBoostingClassifier__max_features': ('auto', 'sqrt', 'log2')\n",
    "        }\n",
    "    elif tecnica == 'KNeighborsClassifier':\n",
    "        parametros = {\n",
    "            'KNeighborsClassifier__n_neighbors': [3,5,7,9],\n",
    "            'KNeighborsClassifier__weights': ('uniform', 'distance'),\n",
    "            'KNeighborsClassifier__algorithm': ('auto', 'ball_tree', 'kd_tree', 'brute'),\n",
    "            'KNeighborsClassifier__p': [1,2]\n",
    "        }\n",
    "    elif tecnica == 'LabelPropagation':\n",
    "        parametros = {\n",
    "            'LabelPropagation__kernel': ('knn', 'rbf'),\n",
    "            'LabelPropagation__n_neighbors': [3,5,7,9],\n",
    "            'LabelPropagation__max_iter': [100, 1000, 10000],\n",
    "            'LabelPropagation__tol': [0.01, 0.001, 0.0001]\n",
    "        }\n",
    "    elif tecnica == 'LabelSpreading':\n",
    "        parametros = {\n",
    "            'LabelSpreading__kernel': ('knn', 'rbf'),\n",
    "            'LabelSpreading__n_neighbors': [3,5,7,9],\n",
    "            'LabelSpreading__max_iter': [100, 1000, 10000],\n",
    "            'LabelSpreading__tol': [0.01, 0.001, 0.0001]\n",
    "        }\n",
    "    elif tecnica == 'LinearDiscriminantAnalysis':\n",
    "        parametros = {\n",
    "            'LinearDiscriminantAnalysis__solver': ('svd', 'lsqr'),\n",
    "            #'LinearDiscriminantAnalysis__shrinkage': (None, 'auto'),\n",
    "            'LinearDiscriminantAnalysis__tol': [0.001, 0.0001, 0.00001]\n",
    "        }\n",
    "    elif tecnica == 'LinearSVC':\n",
    "        parametros = {\n",
    "            #'LinearSVC__penalty': ('l1', 'l2'),\n",
    "            'LinearSVC__loss': ('hinge', 'squared_hinge'),\n",
    "            #'LinearSVC__dual': [True, False],\n",
    "            'LinearSVC__tol': [0.001, 0.0001, 0.00001],\n",
    "            'LinearSVC__multi_class': ('ovr', 'crammer_singer'),\n",
    "            'LinearSVC__fit_intercept': [True, False],\n",
    "            'LinearSVC__max_iter': [100, 1000, 10000]\n",
    "        }\n",
    "    elif tecnica == 'LogisticRegression':\n",
    "        parametros = {\n",
    "            #'LogisticRegression__penalty': ('l2'),\n",
    "            'LogisticRegression__fit_intercept': [True, False],\n",
    "            'LogisticRegression__solver': ('newton-cg', 'sag', 'lbfgs'),\n",
    "            'LogisticRegression__max_iter': [10, 100, 1000, 10000],\n",
    "            'LogisticRegression__warm_start': [True, False]\n",
    "        }\n",
    "    elif tecnica == 'LogisticRegressionCV':\n",
    "        parametros = {\n",
    "            'LogisticRegressionCV__fit_intercept': [True, False],\n",
    "            'LogisticRegressionCV__cv': ['warn', 3, 5, 7, 9],\n",
    "            'LogisticRegressionCV__solver': ('newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'),\n",
    "            'LogisticRegressionCV__refit': [True, False],\n",
    "            'LogisticRegressionCV__multi_class': ('ovr', 'auto')\n",
    "        }\n",
    "    elif tecnica == 'MLPClassifier':\n",
    "        parametros = {\n",
    "            'MLPClassifier__hidden_layer_sizes': [(1,), (100,), (500,), (1,3), (100,3), (500,3)],\n",
    "            'MLPClassifier__activation': ('identity', 'logistic', 'tanh', 'relu'),\n",
    "            'MLPClassifier__solver': ('lbfgs', 'sgd', 'adam'),\n",
    "            'MLPClassifier__learning_rate': ('constant', 'invscaling', 'adaptive'),\n",
    "            'MLPClassifier__shuffle': [True, False],\n",
    "            'MLPClassifier__max_iter': [100, 500, 1000],\n",
    "            'MLPClassifier__tol': [0.001, 0.0001, 0.00001]\n",
    "        }\n",
    "    elif tecnica == 'MultinomialNB':\n",
    "        parametros = {\n",
    "            'MultinomialNB__alpha': [0.0, 1.0],\n",
    "            'MultinomialNB__fit_prior': [True, False]\n",
    "        }\n",
    "    elif tecnica == 'NuSVC':\n",
    "        parametros = {\n",
    "            'NuSVC__kernel': ('linear', 'poly', 'rbf', 'sigmoid', 'precomputed'),\n",
    "            'NuSVC__gamma': ('rbf', 'poly', 'sigmoid'),\n",
    "            'NuSVC__shrinking': [True, False],\n",
    "            'NuSVC__decision_function_shape': ('ovo', 'ovr')\n",
    "        }\n",
    "    elif tecnica == 'PassiveAggressiveClassifier':\n",
    "        parametros = {\n",
    "            'PassiveAggressiveClassifier__fit_intercept': [True, False],\n",
    "            'PassiveAggressiveClassifier__shuffle': [True, False],\n",
    "            'PassiveAggressiveClassifier__loss': ('hinge', 'squared_hinge'),\n",
    "            'PassiveAggressiveClassifier__average': [True, False]\n",
    "        }\n",
    "    elif tecnica == 'Perceptron':\n",
    "        parametros = {\n",
    "            'Perceptron__penalty': (None, 'l1', 'l2', 'elasticnet'),\n",
    "            'Perceptron__shuffle': [True, False]\n",
    "        }\n",
    "    elif tecnica == 'QuadraticDiscriminantAnalysis':\n",
    "        parametros = {\n",
    "            'QuadraticDiscriminantAnalysis__store_covariance': [True, False],\n",
    "            'QuadraticDiscriminantAnalysis__store_covariances': [True, False],\n",
    "            'QuadraticDiscriminantAnalysis__tol': [0.001, 0.0001, 0.00001]\n",
    "        }\n",
    "    elif tecnica == 'RadiusNeighborsClassifier':\n",
    "        parametros = {\n",
    "            'RadiusNeighborsClassifier__weights': ('uniform', 'distance'),\n",
    "            'RadiusNeighborsClassifier__algorithm': ('ball_tree', 'kd_tree', 'brute', 'auto'),\n",
    "            'RadiusNeighborsClassifier__p': [1, 2]\n",
    "        }\n",
    "    elif tecnica == 'RandomForestClassifier':\n",
    "        parametros = {\n",
    "            'RandomForestClassifier__criterion': ('gini', 'entropy'),\n",
    "            'RandomForestClassifier__max_features': ('auto', 'sqrt', 'log2', None),\n",
    "            #'RandomForestClassifier__bootstrap': [True, False],\n",
    "            #'RandomForestClassifier__oob_score': [True, False],\n",
    "            'RandomForestClassifier__warm_start': [True, False],\n",
    "            'RandomForestClassifier__class_weight': ('balanced', 'balanced_subsample', None)\n",
    "        }\n",
    "    elif tecnica == 'RidgeClassifier':\n",
    "        parametros = {\n",
    "            'RidgeClassifier__fit_intercept': [True, False],\n",
    "            'RidgeClassifier__normalize': [True, False],\n",
    "            'RidgeClassifier__solver': ('auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga'),\n",
    "            'RidgeClassifier__tol': [0.01, 0.001, 0.0001]\n",
    "        }\n",
    "    elif tecnica == 'RidgeClassifierCV':\n",
    "        parametros = {\n",
    "            'RidgeClassifierCV__fit_intercept': [True, False],\n",
    "            'RidgeClassifierCV__normalize': [True, False],\n",
    "            'RidgeClassifierCV__cv': [3,5,7,9]\n",
    "        }\n",
    "    elif tecnica == 'SGDClassifier':\n",
    "        parametros = {\n",
    "            'SGDClassifier__loss': ('hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron'),\n",
    "            'SGDClassifier__shuffle': [True, False],\n",
    "            #'SGDClassifier__learning_rate': ['constant', 'optimal', 'invscaling'],\n",
    "            'SGDClassifier__average': [True, False]\n",
    "        }\n",
    "    \n",
    "        \n",
    "    return parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para retornar número aleatório\n",
    "def getNumeroAleatorio(tipo, maximo=None):\n",
    "    if tipo == 'cross_validation':\n",
    "        return random.randint(3,10)\n",
    "    elif tipo == 'random_state':\n",
    "        return random.randint(1, 42)\n",
    "    elif tipo == 'simples':\n",
    "        return random.randint(0,maximo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para ler e retornar em pandas o csv contendo os melhores resultados das técnicas\n",
    "def getMelhoresResultados():\n",
    "    return pd.read_csv('melhores_resultados_tecnicas.csv', sep=';', decimal=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função que lê o arquivo (csv) dos melhores resultados das técnicas e retorna o melhor resultado já alcançado pela técnica naquela ação \n",
    "def getMelhorResultadoTecnica(acao, tecnica):\n",
    "    \n",
    "    melhor_resultado = getMelhoresResultados()\n",
    "    \n",
    "    return melhor_resultado.loc[(melhor_resultado['acao'] == acao) & (melhor_resultado['tecnica'] == tecnica)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para gravar no arquivo (csv) dos melhores resultados das técnicas, o novo resultado/desempenho melhor alcançado/encontrado\n",
    "def salvarResultadoMelhor(tipo, resultado_melhor):\n",
    "    gravarLog('desempenho melhor', 'ação: ' + str(resultado_melhor.iloc[0]['acao']) + ', técnica: ' + str(resultado_melhor.iloc[0]['tecnica']))\n",
    "    \n",
    "    resultados = getMelhoresResultados()\n",
    "    \n",
    "    if tipo == 'novo': # Se o resultado melhor for do tipo novo, significa que não existe nenhum resultado já salvo para a ação e técnica, será adicionado esse novo resultado no arquivo de controle\n",
    "        resultados['n_execucoes_melhores'] = int(1) # Iniciando contador que vai identificar quantas execuções teve na ação e técnica\n",
    "        resultados = pd.concat([resultados, resultado_melhor])\n",
    "    elif tipo == 'melhor': # Se o resultado melhor for do tipo novo, significa que já existe salvo um resultado anterior para a ação e técnica, então esse resultado anterior já salvo será substituido pelo novo resultado melhor\n",
    "        # Incrementando contador que identifica quantas execuções teve na ação e técnica\n",
    "        resultados.loc[(resultados['acao'] == resultado_melhor.iloc[0]['acao']) & (resultados['tecnica'] == resultado_melhor.iloc[0]['tecnica']), 'n_execucoes_melhores'] += 1\n",
    "\n",
    "        for coluna in resultados.columns: # Percorrer todas as colunas, e salvar nas colunas que representa os avaliadores de desempenho, o novo melhor resultado\n",
    "            if ((coluna != 'tecnica') and (coluna != 'acao') and (coluna != 'tipo_split') and (coluna != 'pipeline') and (coluna != 'parametros') \n",
    "                and (coluna != 'best_estimator') and (coluna != 'best_params') and (coluna != 'n_execucoes_melhores')):\n",
    "                resultados.loc[(resultados['acao'] == resultado_melhor.iloc[0]['acao']) & (resultados['tecnica'] == resultado_melhor.iloc[0]['tecnica']), coluna] = resultado_melhor.iloc[0][coluna]\n",
    "        \n",
    "    # Salvar o arquivo com o novo melhor resultado incluso\n",
    "    arquivo = open('melhores_resultados_tecnicas.csv', 'w')\n",
    "    resultados.to_csv(arquivo, sep=';', index=False, decimal=',')\n",
    "    arquivo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função que recebe o y_true e y_pred, aplica os avaliadores de desempenho, faz o comparativo se o desempenho melhorou, e se tiver melhorado chama a função para salvar o novo desempenho no arquivo de controle (csv), posteriormente o modelo desse novo desempenho será salvo pelo joblib (.pkl)\n",
    "def avaliarDesempenho(acao, tecnica, y_true, y_pred):\n",
    "    \n",
    "    resultados = {}\n",
    "    resultados['acao'] = [acao]\n",
    "    resultados['tecnica'] = [tecnica]\n",
    "    # Aplicando avaliadores de desempenho\n",
    "    resultados['accuracy'] = [sklearn.metrics.accuracy_score(y_true, y_pred)]\n",
    "    resultados['roc_auc_score'] = [sklearn.metrics.roc_auc_score(y_true, y_pred)]\n",
    "    resultados['f1_score'] = [sklearn.metrics.f1_score(y_true, y_pred)]\n",
    "    resultados['log_loss'] = [sklearn.metrics.log_loss(y_true, y_pred)]\n",
    "    resultados['precision'] = [sklearn.metrics.precision_score(y_true, y_pred)]\n",
    "    resultados['recall'] = [sklearn.metrics.recall_score(y_true, y_pred)]\n",
    "    \n",
    "    \n",
    "    pd_resultados = pd.DataFrame(data=resultados)\n",
    "    \n",
    "    melhor_resultado_anterior = getMelhorResultadoTecnica(acao, tecnica)\n",
    "    \n",
    "    melhorou = False\n",
    "    tipo = ''\n",
    "    \n",
    "    if len(melhor_resultado_anterior) > 0: # Verificar se existe algum resultado já salvo para aquela ação e técnica, se já existir é feito o comparativo para verificar se o desempenho atual é melhor do que o melhor desempenho já salvo/encontrado\n",
    "        \n",
    "        contador = 0 # Variável para contar em quantos avaliadores de desempenho o modelo atual é melhor se comparado com o melhor modelo já salvo/encontrado\n",
    "        for avaliador in pd_resultados.columns:\n",
    "            if (avaliador != 'tecnica') and (avaliador != 'acao') and (avaliador != 'accuracy'): # Verificar se a coluna é um avaliador ou não, somente passará se a coluna for um avaliador. A acurácia não será usada no comparativo pois ela não é uma boa metrica para quando se tem dados desbalanceados\n",
    "                \n",
    "                if avaliador == 'log_loss': # Para o avaliador log_loss, quanto menor o valor, melhor é o desempenho\n",
    "                    if float(pd_resultados[avaliador]) < float(melhor_resultado_anterior[avaliador]):\n",
    "                        contador += 1\n",
    "                elif float(pd_resultados[avaliador]) > float(melhor_resultado_anterior[avaliador]): # Para o restante dos avaliadores, quanto maior o valor melhor é o desempenho\n",
    "                    contador += 1\n",
    "\n",
    "        \n",
    "        metade = 5 / 2 # quantidade de avaliadores (que estamos usando 5) dividido por 2\n",
    "        if contador > metade: # Se teve mais da metade de avaliadores com desempenho melhor, então consideramos que o modelo é melhor do que o melhor modelo já salvo/encontrado anteriormente\n",
    "            melhorou = True\n",
    "            pd_resultados['quantos_avaliadores_melhores_que_o_antecessor'] = contador\n",
    "            tipo = 'melhor'\n",
    "    \n",
    "    else: # Caso não existe nenhum resultado já salvo para a ação e técnica, então o primeiro modelo será considerado como melhor\n",
    "        \n",
    "        melhorou = True\n",
    "        pd_resultados['quantos_avaliadores_melhores_que_o_antecessor'] = -1 # -1 representa que não existe número para este atributos\n",
    "        tipo = 'novo'\n",
    "\n",
    "    return melhorou, tipo, pd_resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função que executa todas as etapas necessárias para ler os dados da ação, montar o pipeline, coletar os parâmetros, realizar o random search e avaliar o desempenho da técnica\n",
    "def robo(acao):\n",
    "\n",
    "    try:\n",
    "\n",
    "        gravarLog('info', 'Iniciando execução com a ação: ' + acao)\n",
    "\n",
    "        X, y = getDadosAcao(acao) # Coletando os dados referente a ação\n",
    "        tamanho_base_completa = len(X) # Salvar quantidade/tamanho de linhas/tuplas\n",
    "\n",
    "        X_train, X_test, y_train, y_test, tipo_split, random_state_split = splitDados(X, y) # Separando os dados em treino e teste\n",
    "        tem_dados_de_teste_nos_dados_de_treino = X_test.isin(X_train).values.any()\n",
    "\n",
    "        # Limpar memória apagando variável que não será mais utilizada\n",
    "        del(X)\n",
    "        del(y)\n",
    "\n",
    "        pipeline = []\n",
    "        parametros = {}\n",
    "\n",
    "        normalizador_pipeline, normalizador_parametros = getNormalizador() # Coletando o normalizador, que será definido aleatoriamente\n",
    "        if len(normalizador_pipeline) > 0: # Se for definido que terá normalizador, o normalizador é adicionado no pipeline e no array que salva os parâmetros\n",
    "            pipeline += [normalizador_pipeline]\n",
    "            parametros.update(normalizador_parametros)\n",
    "\n",
    "        redutor_dimensionalidade_pipeline, redutor_dimensionalidade_parametros = getRedutorDimensionalidade() # Coletando o redutor de dimensionalidade, que será definido aleatoriamente\n",
    "        if len(redutor_dimensionalidade_pipeline) > 0: # Se for definido que terá redutor de dimensionalidade, o redutor de dimensionalidade é adicionado no pipeline e no array que salva os parâmetros\n",
    "            pipeline += [redutor_dimensionalidade_pipeline]\n",
    "            parametros.update(redutor_dimensionalidade_parametros)\n",
    "\n",
    "\n",
    "        for tecnica, model in tecnicas: # Para cada técnica presente na variável \"tecnicas\", coletar os parametros da técnica, realizar o random search e avaliar o seu desempenho\n",
    "\n",
    "            try:\n",
    "\n",
    "                pipeline_tecnica = pipeline.copy()\n",
    "                pipeline_tecnica += [(tecnica, model)] # Adicionando a técnica no pipeline\n",
    "\n",
    "                parametros_tecnica = parametros.copy()\n",
    "                parametros_tecnica.update(getParametrosTecnica(tecnica)) # Coletando os parâmetros da técnica e adicionando no array de parametros\n",
    "\n",
    "                pipeline_final = Pipeline(pipeline_tecnica)\n",
    "\n",
    "                cross_validation = getNumeroAleatorio('cross_validation') # Coletando um número aleatório para representar o cross_validation do random_search\n",
    "                random_state = getNumeroAleatorio('random_state') # Coletando um número aleatório para representar o random_state do random_search\n",
    "\n",
    "                # Executando o Random Search com 4 iterações\n",
    "                modelo = RandomizedSearchCV(n_iter=4, estimator=pipeline_final, param_distributions=parametros_tecnica, cv=cross_validation, random_state=random_state)\n",
    "\n",
    "                modelo.fit(X_train, y_train)\n",
    "\n",
    "                y_pred = modelo.predict(X_test) # Realizando a predição para os dados de teste\n",
    "\n",
    "                # Chamando a função que avalia o desempenho da técnica e retorna se o desempenho foi melhor ou não (True ou False)\n",
    "                melhorou, tipo, desempenho_tecnica = avaliarDesempenho(acao, tecnica, y_test, y_pred)\n",
    "\n",
    "                # Adicionando informações relevantes e informações para identificar como é o modelo gerado, permitindo que seja reproduzido manualmente caso necessário\n",
    "                desempenho_tecnica['tipo_split'] = [tipo_split]\n",
    "                desempenho_tecnica['pipeline'] = [str(pipeline_tecnica)]\n",
    "                desempenho_tecnica['parametros'] = [str(parametros_tecnica)]\n",
    "                desempenho_tecnica['best_estimator'] = [modelo.best_estimator_]\n",
    "                desempenho_tecnica['best_params'] = [modelo.best_params_]\n",
    "                desempenho_tecnica['random_state_split'] = [random_state_split]\n",
    "                desempenho_tecnica['random_state_random_search'] = [random_state]\n",
    "                desempenho_tecnica['cross_validation_random_search'] = [cross_validation]\n",
    "                desempenho_tecnica['tamanho_base_treino'] = [len(X_train)]\n",
    "                desempenho_tecnica['tamanho_base_teste'] = [len(X_test)]\n",
    "                desempenho_tecnica['tamanho_base_completa'] = [tamanho_base_completa]\n",
    "                desempenho_tecnica['tem_dados_de_teste_nos_dados_de_treino'] = [tem_dados_de_teste_nos_dados_de_treino]\n",
    "\n",
    "                gravarLog('resultado', desempenho_tecnica)\n",
    "\n",
    "\n",
    "                if melhorou is True: # Se o desempenho tiver sido melhor, o modelo da técnica será salvo pelo joblib (.pkl)\n",
    "\n",
    "                    nome_arquivo = 'modelos/' + acao + '_' + tecnica + '.pkl' # Criando o nome do arquivo, ex.: PETR4_KNeighborsClassifier.pkl\n",
    "                    sklearn.externals.joblib.dump(modelo.best_estimator_, nome_arquivo) # Salvando o modelo\n",
    "                    salvarResultadoMelhor(tipo, desempenho_tecnica) # Salvando novo resultado melhor\n",
    "                    print('----------------- ' + str(datetime.now()) + ', ação: ' + acao + ', técnica: ' + tecnica + ', melhorou -------------')\n",
    "\n",
    "                    # Salvando y_test e y_pred para futuras verificações caso necessário\n",
    "                    y_test.to_csv('log/y_test_pred/' + acao + '_' + tecnica + '_y_test.csv', index=False, header=True)\n",
    "                    pd.DataFrame(y_pred, columns=['y_pred']).to_csv('log/y_test_pred/' + acao + '_' + tecnica + '_y_pred.csv', index=False)\n",
    "\n",
    "            except:\n",
    "                print('*********** ' + str(datetime.now()) + ', ação: ' + acao + ', técnica: ' + tecnica + ', erro_fit ***********')\n",
    "                gravarLog('erro', 'erro durante o fit, ação: ' + acao + ', técnica: ' + tecnica)\n",
    "                \n",
    "                pass\n",
    "\n",
    "            del(pipeline_tecnica)\n",
    "            del(parametros_tecnica)\n",
    "\n",
    "        gravarLog('info', 'Finalizado execução com a ação: ' + acao)\n",
    "\n",
    "    except:\n",
    "        \n",
    "        print('*********** erro_geral, ação: ' + acao + ' ***********')\n",
    "        gravarLog('erro', 'erro geral, ação: ' + acao)\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- 2018-10-29 14:24:46.050435, ação: PETR4, técnica: DecisionTreeClassifier, melhorou -------------\n",
      "----------------- 2018-10-29 14:24:47.041655, ação: PETR4, técnica: ExtraTreeClassifier, melhorou -------------\n"
     ]
    }
   ],
   "source": [
    "robo('PETR4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1280"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acoes = dados.CODNEG.unique()\n",
    "len(acoes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,100000000000000000000000000000):\n",
    "    random.shuffle(acoes)\n",
    "    for acao in acoes:\n",
    "        robo(acao)\n",
    "    #Parallel(n_jobs=multiprocessing.cpu_count())(delayed(teste)(acao) for acao in acoes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pd.read_csv('log/y_test_pred/ABCB4_BernoulliNB_y_pred.csv')\n",
    "y_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = pd.read_csv('log/y_test_pred/ABCB4_BernoulliNB_y_test.csv')\n",
    "y_true.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('accuracy_score: ' + str(sklearn.metrics.accuracy_score(y_true, y_pred)))\n",
    "print('roc_auc_score: ' + str(sklearn.metrics.roc_auc_score(y_true, y_pred)))\n",
    "print('log_loss: ' + str(sklearn.metrics.log_loss(y_true, y_pred)))\n",
    "print('f1_score: ' + str(sklearn.metrics.f1_score(y_true, y_pred)))\n",
    "print('precision_score: ' + str(sklearn.metrics.precision_score(y_true, y_pred)))\n",
    "print('recall_score: ' + str(sklearn.metrics.recall_score(y_true, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sklearn.metrics.classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testando agora com ELPL3F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pd.read_csv('log/y_test_pred/ELPL3F_BernoulliNB_y_pred.csv')\n",
    "y_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = pd.read_csv('log/y_test_pred/ELPL3F_BernoulliNB_y_test.csv')\n",
    "y_true.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('accuracy_score: ' + str(sklearn.metrics.accuracy_score(y_true, y_pred)))\n",
    "print('roc_auc_score: ' + str(sklearn.metrics.roc_auc_score(y_true, y_pred)))\n",
    "print('log_loss: ' + str(sklearn.metrics.log_loss(y_true, y_pred)))\n",
    "print('f1_score: ' + str(sklearn.metrics.f1_score(y_true, y_pred)))\n",
    "print('precision_score: ' + str(sklearn.metrics.precision_score(y_true, y_pred)))\n",
    "print('recall_score: ' + str(sklearn.metrics.recall_score(y_true, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sklearn.metrics.classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
